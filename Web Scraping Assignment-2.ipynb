{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name,experience_required. You have to scrape first 10 jobs data.This task will be done in following steps:¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first get the webpage https://www.naukri.com/\n",
    "Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "Then click the search button.\n",
    "Then scrape the data for the first 10 jobs results you get.\n",
    "Finally create a dataframe of the scraped data. Note- All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "location=driver.find_element_by_id('qsb-location-sugg')\n",
    "search.send_keys('Data Analyst')\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "company_name=[]\n",
    "location=[]\n",
    "experience=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title:\n",
    "    job_title.append(i.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "company=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for j in company:\n",
    "    company_name.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_all=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for k in location_all:\n",
    "    location.append(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_all=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for l in experience_all:\n",
    "    experience.append(l.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "job=pd.DataFrame({})\n",
    "job['Designation']=job_title[0:10]\n",
    "job['Company']=company_name[0:10]\n",
    "job['Location']=location[0:10]\n",
    "job['Experience']=experience[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Super India Tech Mark</td>\n",
       "      <td>Bangalore/Bengaluru(Devalapur)</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>tech mahindra ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CONDUENT BUSINESS SERVICES INDIA LLP</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Concentrix Daksh Services India Private Limited.</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>WEIWO Communication Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru(Ulsoor)</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Cerner</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Cerner Corporation</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Designation                                           Company  \\\n",
       "0             Data Analyst                             Super India Tech Mark   \n",
       "1             Data Analyst                                 tech mahindra ltd   \n",
       "2             Data Analyst              CONDUENT BUSINESS SERVICES INDIA LLP   \n",
       "3             Data Analyst           GlaxoSmithKline Pharmaceuticals Limited   \n",
       "4             Data Analyst                          Myntra Designs Pvt. Ltd.   \n",
       "5             Data Analyst                          Myntra Designs Pvt. Ltd.   \n",
       "6  Hiring For Data Analyst  Concentrix Daksh Services India Private Limited.   \n",
       "7             Data Analyst                     WEIWO Communication Pvt. Ltd.   \n",
       "8      Senior Data Analyst                                            Cerner   \n",
       "9      Senior Data Analyst                                Cerner Corporation   \n",
       "\n",
       "                                            Location Experience  \n",
       "0                     Bangalore/Bengaluru(Devalapur)    0-2 Yrs  \n",
       "1                                Bangalore/Bengaluru    4-8 Yrs  \n",
       "2                                Bangalore/Bengaluru    1-2 Yrs  \n",
       "3                                Bangalore/Bengaluru    2-7 Yrs  \n",
       "4                                Bangalore/Bengaluru    3-6 Yrs  \n",
       "5                                Bangalore/Bengaluru    4-8 Yrs  \n",
       "6  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...    2-7 Yrs  \n",
       "7                        Bangalore/Bengaluru(Ulsoor)    5-8 Yrs  \n",
       "8                                Bangalore/Bengaluru    3-5 Yrs  \n",
       "9                                Bangalore/Bengaluru    4-9 Yrs  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first get the webpage https://www.naukri.com/\n",
    "Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "Then click the search button.\n",
    "Then scrape the data for the first 10 jobs results you get.\n",
    "Finally create a dataframe of the scraped data. Note- 1. All of the above steps have to be done in code. No step is to be done manually. WEB SCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_designation=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_location=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_designation.send_keys('Data Scientist')\n",
    "search_location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "job_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title:\n",
    "    job_title.append(i.text)\n",
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for j in location:\n",
    "    job_location.append(j.text)\n",
    "company=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for k in company:\n",
    "    company_name.append(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")]\n",
    "for url in urls[0:10]:\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//section[@class='job-desc']/div[1]\").text\n",
    "        description=raw_description.replace('\\n','')\n",
    "        description=raw_description.replace(\"Contact Person\",\"@@@@@\")\n",
    "        description= description.split(\"@@@@@\")\n",
    "        job_description.append(description[0])\n",
    "    except NoSuchElementException :\n",
    "        job_description.append(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "job=pd.DataFrame({})\n",
    "job['Title']=job_title[0:10]\n",
    "job['Company']=company_name[0:10]\n",
    "job['Location']=job_location[0:10]\n",
    "job['Description']=job_description[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>CronJ IT Technologies Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Responsibilities and Duties\\nCreate innovative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Opportunity For Data Scientist Internship - Be...</td>\n",
       "      <td>Corner Stone Solutions</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Location - Bangalore / Bengaluru\\nDuration- 6 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist/ Analyst</td>\n",
       "      <td>Becton Dickinson India Pvt. Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Roles and Responsibilities\\nob Description Sum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Roles and Responsibilities\\n\\n\\n- Selecting fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist || Data Analyst || Data science</td>\n",
       "      <td>Inspiration Manpower Consultancy Pvt. Ltd.</td>\n",
       "      <td>Navi Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Job description\\nJob Summary and Key Responsib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DBCG IND - GAMMA Senior Data Scientist</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>What Youll Do\\n\\nWe re looking for a passi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist/Senior Data Scientist</td>\n",
       "      <td>GANIT BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>About Ganit Inc\\n\\nFounded by senior industry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Roles and Responsibilities\\n\\nMust have strong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Global Medical Data Scientist</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Associate Data Scientist - CRM &amp; Loyalty</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>The Role\\nGeneral Position Definition\\nThis ro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                     Data Scientist   \n",
       "1  Opportunity For Data Scientist Internship - Be...   \n",
       "2                            Data Scientist/ Analyst   \n",
       "3                  Data Scientist - Machine Learning   \n",
       "4     Data Scientist || Data Analyst || Data science   \n",
       "5             DBCG IND - GAMMA Senior Data Scientist   \n",
       "6               Data Scientist/Senior Data Scientist   \n",
       "7  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "8                      Global Medical Data Scientist   \n",
       "9           Associate Data Scientist - CRM & Loyalty   \n",
       "\n",
       "                                      Company  \\\n",
       "0       CronJ IT Technologies Private Limited   \n",
       "1                      Corner Stone Solutions   \n",
       "2             Becton Dickinson India Pvt. Ltd   \n",
       "3                                 AugmatrixGo   \n",
       "4  Inspiration Manpower Consultancy Pvt. Ltd.   \n",
       "5                     Boston Consulting Group   \n",
       "6    GANIT BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "7                                    CES Ltd.   \n",
       "8     GlaxoSmithKline Pharmaceuticals Limited   \n",
       "9         Shell India Markets Private Limited   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                   Navi Mumbai, Bangalore/Bengaluru   \n",
       "5    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "6  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "7  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                         Description  \n",
       "0  Responsibilities and Duties\\nCreate innovative...  \n",
       "1  Location - Bangalore / Bengaluru\\nDuration- 6 ...  \n",
       "2  Roles and Responsibilities\\nob Description Sum...  \n",
       "3  Roles and Responsibilities\\n\\n\\n- Selecting fe...  \n",
       "4  Job description\\nJob Summary and Key Responsib...  \n",
       "5      What Youll Do\\n\\nWe re looking for a passi...  \n",
       "6  About Ganit Inc\\n\\nFounded by senior industry ...  \n",
       "7  Roles and Responsibilities\\n\\nMust have strong...  \n",
       "8                                                ---  \n",
       "9  The Role\\nGeneral Position Definition\\nThis ro...  "
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below: You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company_name,experience_required. The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs. The task will be done as shown in the below steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first get the webpage https://www.naukri.com/\n",
    "Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "Then click the search button.\n",
    "Then apply the location filter and salary filter by checking the respective boxes\n",
    "Then scrape the data for the first 10 jobs results you get.\n",
    "Finally create a dataframe of the scraped data. Note- All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "Company_name=[]\n",
    "job_location=[]\n",
    "Experienced_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element_by_xpath(\"//span[@title='Delhi / NCR']\")\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary=driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist - IBM Garage',\n",
       " 'Data Scientist/Data Analyst - Python/Machine Learning',\n",
       " 'Females Required- Data Scientist- Noida',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - Python & Machine Learning',\n",
       " 'Data Scientist - Python & Machine Learning',\n",
       " 'Data Scientist - Python / Machine Learning / Tableau / Power BI',\n",
       " 'Data Scientist - Python & Machine Learning',\n",
       " 'Required- Data Scientist (NLP)-Axis Bank - 6 months contract',\n",
       " 'Data Scientist - Python / Machine Learning / Tableau / Power BI']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title[:10]:\n",
    "    job_title.append(i.text)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IBM India Pvt. Limited',\n",
       " 'Change leaders',\n",
       " 'Randstad',\n",
       " 'Amity University',\n",
       " 'FUTURES AND CAREERS',\n",
       " 'FUTURES AND CAREERS',\n",
       " 'FUTURES AND CAREERS',\n",
       " 'FUTURES AND CAREERS',\n",
       " 'Axis Bank Limited',\n",
       " 'FUTURES AND CAREERS']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for j in company[:10]:\n",
    "    Company_name.append(j.text)\n",
    "Company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Mumbai, Ghaziabad',\n",
       " 'Noida, Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Ghaziabad, Faridabad, Delhi / NCR',\n",
       " 'Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Mumbai, Hyderabad/Secunderabad, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Kolkata, New Delhi, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru, Delhi / NCR']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for k in location[:10]:\n",
    "    job_location.append(k.text)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5-8 Yrs',\n",
       " '5-10 Yrs',\n",
       " '3-7 Yrs',\n",
       " '6-8 Yrs',\n",
       " '2-7 Yrs',\n",
       " '2-7 Yrs',\n",
       " '3-8 Yrs',\n",
       " '2-7 Yrs',\n",
       " '4-9 Yrs',\n",
       " '3-8 Yrs']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "for l in experience[:10]:\n",
    "    Experienced_required.append(l.text)\n",
    "Experienced_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist/Data Analyst - Python/Machine L...</td>\n",
       "      <td>Change leaders</td>\n",
       "      <td>Mumbai, Ghaziabad</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Females Required- Data Scientist- Noida</td>\n",
       "      <td>Randstad</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amity University</td>\n",
       "      <td>Ghaziabad, Faridabad, Delhi / NCR</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengal...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Python / Machine Learning / T...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Required- Data Scientist (NLP)-Axis Bank - 6 m...</td>\n",
       "      <td>Axis Bank Limited</td>\n",
       "      <td>Kolkata, New Delhi, Hyderabad/Secunderabad, Pu...</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Python / Machine Learning / T...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title                 Company  \\\n",
       "0                        Data Scientist - IBM Garage  IBM India Pvt. Limited   \n",
       "1  Data Scientist/Data Analyst - Python/Machine L...          Change leaders   \n",
       "2            Females Required- Data Scientist- Noida                Randstad   \n",
       "3                                     Data Scientist        Amity University   \n",
       "4         Data Scientist - Python & Machine Learning     FUTURES AND CAREERS   \n",
       "5         Data Scientist - Python & Machine Learning     FUTURES AND CAREERS   \n",
       "6  Data Scientist - Python / Machine Learning / T...     FUTURES AND CAREERS   \n",
       "7         Data Scientist - Python & Machine Learning     FUTURES AND CAREERS   \n",
       "8  Required- Data Scientist (NLP)-Axis Bank - 6 m...       Axis Bank Limited   \n",
       "9  Data Scientist - Python / Machine Learning / T...     FUTURES AND CAREERS   \n",
       "\n",
       "                                            Location Experience  \n",
       "0  Noida, Hyderabad/Secunderabad, Bangalore/Benga...    5-8 Yrs  \n",
       "1                                  Mumbai, Ghaziabad   5-10 Yrs  \n",
       "2               Noida, Gurgaon/Gurugram, Delhi / NCR    3-7 Yrs  \n",
       "3                  Ghaziabad, Faridabad, Delhi / NCR    6-8 Yrs  \n",
       "4  Hyderabad/Secunderabad, Pune, Bangalore/Bengal...    2-7 Yrs  \n",
       "5  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...    2-7 Yrs  \n",
       "6  Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...    3-8 Yrs  \n",
       "7  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...    2-7 Yrs  \n",
       "8  Kolkata, New Delhi, Hyderabad/Secunderabad, Pu...    4-9 Yrs  \n",
       "9  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...    3-8 Yrs  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job=pd.DataFrame({'Title':job_title,'Company':Company_name,'Location':job_location,'Experience':Experienced_required})\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.glassdoor.co.in/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='sc.keyword']\"))).send_keys(\"Data Scientist\")\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='sc.location']\"))).send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATHzz,\"//button[@data-test='search-bar-submit']\"))).click()\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_ratings=[]\n",
    "company_name=[]\n",
    "days_ago=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Telstra', 'NetApp', 'Intuit', 'Western Digital']"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies=driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']/span[1]\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.9', '4.3', '4.4', '3.7']"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings=driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\")\n",
    "for i in ratings:\n",
    "    if i.text is None :\n",
    "        company_ratings.append(\"--\") \n",
    "    else:\n",
    "        company_ratings.append(i.text)\n",
    "company_ratings[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '4']"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days=driver.find_elements_by_xpath(\"//div[@data-test='job-age']\")\n",
    "for i in days:\n",
    "    if i.text is None :\n",
    "        days_ago.append(\"--\") \n",
    "    else:\n",
    "        days_ago.append(i.text[0])\n",
    "days_ago[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_ratings</th>\n",
       "      <th>days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Telstra</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NetApp</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intuit</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Western Digital</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Telstra</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wabtec</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rolls-Royce</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unnati</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         company_name company_ratings days_ago\n",
       "0             Telstra             3.9        1\n",
       "1              NetApp             4.3        4\n",
       "2              Intuit             4.4        1\n",
       "3     Western Digital             3.7        1\n",
       "4                                 4.1        1\n",
       "5  Ericsson-Worldwide             4.1        3\n",
       "6             Telstra             3.9        1\n",
       "7              Wabtec             3.4        4\n",
       "8         Rolls-Royce             3.3        5\n",
       "9              Unnati             4.9        5"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"company_name\":company_name[0:10],\"company_ratings\":company_ratings[0:10],\"days_ago\":days_ago[0:10]})\n",
    "df[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location. You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary. The above task will be, done as shown in the below steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "Click the search button.\n",
    "After that you will land on the below page You have to scrape whole data from this webpage\n",
    "Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company. 6.Store the data in a dataframe. Note that all of the above steps have to be done by coding only and not manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.glassdoor.co.in/Salaries/index.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='KeywordSearch']\"))).send_keys(\"Data Scientist\")\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='LocationSearch']\"))).send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH,\"//button[@data-test='search-bar-submit']\"))).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_salaries=[]\n",
    "max_salaries=[]\n",
    "average_salaries=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_salary=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[1]\")\n",
    "for i in min_salary:\n",
    "    if i.text is None :\n",
    "        min_salaries.append(\"--\") \n",
    "    else:\n",
    "        min_salaries.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_salary=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[2]\")\n",
    "for i in max_salary:\n",
    "    if i.text is None :\n",
    "        max_salaries.append(\"--\") \n",
    "    else:\n",
    "        max_salaries.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_salary=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")\n",
    "for i in average_salary:\n",
    "    if i.text is None :\n",
    "        average_salaries.append(\"--\") \n",
    "    else:\n",
    "        average_salaries.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "company=driver.find_elements_by_xpath(\"//div[@data-test='job-info']/p[2]\")\n",
    "for i in company:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\")      \n",
    "    else:\n",
    "        company_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Average_salary</th>\n",
       "      <th>Minimum_salary</th>\n",
       "      <th>Maximum_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹ 5,97,967</td>\n",
       "      <td>₹333K</td>\n",
       "      <td>₹1,080K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹ 11,12,243</td>\n",
       "      <td>₹560K</td>\n",
       "      <td>₹2,147K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹ 12,12,741</td>\n",
       "      <td>₹436K</td>\n",
       "      <td>₹11,274K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹ 7,37,972</td>\n",
       "      <td>₹569K</td>\n",
       "      <td>₹2,648K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹ 7,15,984</td>\n",
       "      <td>₹350K</td>\n",
       "      <td>₹1,565K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹ 13,41,900</td>\n",
       "      <td>₹1,037K</td>\n",
       "      <td>₹1,500K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹ 7,90,812</td>\n",
       "      <td>₹487K</td>\n",
       "      <td>₹1,421K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>₹ 11,81,047</td>\n",
       "      <td>₹602K</td>\n",
       "      <td>₹1,644K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹ 9,89,924</td>\n",
       "      <td>₹196K</td>\n",
       "      <td>₹1,755K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹ 11,73,127</td>\n",
       "      <td>₹558K</td>\n",
       "      <td>₹1,500K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company_name Average_salary Minimum_salary Maximum_salary\n",
       "0  Tata Consultancy Services     ₹ 5,97,967          ₹333K        ₹1,080K\n",
       "1                  Accenture    ₹ 11,12,243          ₹560K        ₹2,147K\n",
       "2                  Delhivery    ₹ 12,12,741          ₹436K       ₹11,274K\n",
       "3                        IBM     ₹ 7,37,972          ₹569K        ₹2,648K\n",
       "4         Ericsson-Worldwide     ₹ 7,15,984          ₹350K        ₹1,565K\n",
       "5         UnitedHealth Group    ₹ 13,41,900        ₹1,037K        ₹1,500K\n",
       "6         Valiance Solutions     ₹ 7,90,812          ₹487K        ₹1,421K\n",
       "7                 Innovaccer    ₹ 11,81,047          ₹602K        ₹1,644K\n",
       "8              ZS Associates     ₹ 9,89,924          ₹196K        ₹1,755K\n",
       "9                EXL Service    ₹ 11,73,127          ₹558K        ₹1,500K"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"Company_name\":company_name[0:10],\"Average_salary\":average_salaries[0:10],\"Minimum_salary\":min_salaries[0:10],\"Maximum_salary\":max_salaries[0:10]})\n",
    "df[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search.send_keys('Sunglasses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element_by_class_name(\"_34RNph\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    bd=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for i in bd[:100]:\n",
    "        brand.append(i.text)\n",
    "    pro_des=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    for j in pro_des[:100]:\n",
    "        product_description.append(j.text)\n",
    "    prices=driver.find_elements_by_class_name(\"_30jeq3\")\n",
    "    for k in prices[:100]:\n",
    "        price.append(k.text) \n",
    "    discounts=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "    for l in discounts[:100]:\n",
    "        discount.append(l.text)\n",
    "    \n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='ge-49M']\")\n",
    "    driver.get(nxt_button[page].get_attribute('href'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phenomenal</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (Free Size)</td>\n",
       "      <td>₹299</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BKGE</td>\n",
       "      <td>UV Protection, Polarized Rectangular, Retro Sq...</td>\n",
       "      <td>₹394</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (88)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection, Gradient Round, Cat-eye Sunglas...</td>\n",
       "      <td>₹500</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection, Gradient Oval Sunglasses (58)</td>\n",
       "      <td>₹211</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>DEIXELS</td>\n",
       "      <td>UV Protection Oval Sunglasses (Free Size)</td>\n",
       "      <td>₹210</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Aislin</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (58)</td>\n",
       "      <td>₹474</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>hipe</td>\n",
       "      <td>UV Protection, Mirrored Round Sunglasses (Free...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Butterfly Sunglasses (60)</td>\n",
       "      <td>₹209</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product Description Price  \\\n",
       "0       phenomenal    UV Protection Clubmaster Sunglasses (Free Size)  ₹299   \n",
       "1             BKGE  UV Protection, Polarized Rectangular, Retro Sq...  ₹394   \n",
       "2        ROYAL SON         UV Protection Retro Square Sunglasses (88)  ₹599   \n",
       "3   ROZZETTA CRAFT  UV Protection, Gradient Retro Square Sunglasse...  ₹499   \n",
       "4           Aislin  UV Protection, Gradient Round, Cat-eye Sunglas...  ₹500   \n",
       "..             ...                                                ...   ...   \n",
       "95          Aislin       UV Protection, Gradient Oval Sunglasses (58)  ₹211   \n",
       "96         DEIXELS          UV Protection Oval Sunglasses (Free Size)  ₹210   \n",
       "97          Aislin      UV Protection, Gradient Round Sunglasses (58)  ₹474   \n",
       "98            hipe  UV Protection, Mirrored Round Sunglasses (Free...  ₹499   \n",
       "99          PIRASO            UV Protection Butterfly Sunglasses (60)  ₹209   \n",
       "\n",
       "   Discount  \n",
       "0   85% off  \n",
       "1   78% off  \n",
       "2   70% off  \n",
       "3   75% off  \n",
       "4   70% off  \n",
       "..      ...  \n",
       "95  65% off  \n",
       "96  80% off  \n",
       "97  69% off  \n",
       "98  86% off  \n",
       "99  86% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunglass=pd.DataFrame({})\n",
    "sunglass['Brand']=brand[:100]\n",
    "sunglass['Product Description']=product_description[:100]\n",
    "sunglass['Price']=price[:100]\n",
    "sunglass['Discount']=discount[:100]\n",
    "sunglass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to scrape the tick marked attributes. These are\n",
    "\n",
    "Rating\n",
    "Review_summary\n",
    "Full review\n",
    "You have to scrape the data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium \n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_review=driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\")\n",
    "all_review.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=9\n",
    "for page in range(start,end):\n",
    "    rate=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    for i in rate[:100]:\n",
    "        rating.append(i.text)\n",
    "    rev_sum=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    for j in rev_sum[:100]:\n",
    "        review_summary.append(j.text)\n",
    "    ful_rev=driver.find_elements_by_xpath(\"//div[@class='row']\")\n",
    "    for k in ful_rev:\n",
    "        full_review.append(k.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='ge-49M']\")\n",
    "    driver.get(nxt_button[page].get_attribute('href'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>4.6★\\n44,311 Ratings &amp;\\n3,403 Reviews\\n5★\\n4★\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>4.6★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>4.6★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4.6★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5\\nBrilliant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Ananya Dhiman\\nCertified Buyer, Zirakpur\\n9 mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>11051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>5\\nSimply awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Really good actually this is my first apple pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Likhitha Heman\\nCertified Buyer\\n8 months ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating         Review Summary  \\\n",
       "0       5              Brilliant   \n",
       "1       5       Perfect product!   \n",
       "2       5      Worth every penny   \n",
       "3                                  \n",
       "4                                  \n",
       "..    ...                    ...   \n",
       "94      5                Awesome   \n",
       "95      5              Wonderful   \n",
       "96      5                 Super!   \n",
       "97      5              Must buy!   \n",
       "98      5  Mind-blowing purchase   \n",
       "\n",
       "                                               Review  \n",
       "0   4.6★\\n44,311 Ratings &\\n3,403 Reviews\\n5★\\n4★\\...  \n",
       "1                                                4.6★  \n",
       "2                                                4.6★  \n",
       "3                                                4.6★  \n",
       "4                                        5\\nBrilliant  \n",
       "..                                                ...  \n",
       "94  Ananya Dhiman\\nCertified Buyer, Zirakpur\\n9 mo...  \n",
       "95                                              11051  \n",
       "96                                  5\\nSimply awesome  \n",
       "97  Really good actually this is my first apple pr...  \n",
       "98      Likhitha Heman\\nCertified Buyer\\n8 months ago  \n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone=pd.DataFrame({})\n",
    "iphone['Rating']=rating[:99]\n",
    "iphone['Review Summary']=review_summary[:99]\n",
    "iphone['Review']=full_review[:99]\n",
    "iphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8:Scrape data for first 100 sneakers you find when you visit flipkart.comand search for “sneakers” in the search field.You have to scrape 4 attributes of each sneaker :¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Brand\n",
    "2.Product Description\n",
    "3.Price\n",
    "4.discount % Also note that all the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium \n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element_by_class_name(\"_3704LK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):\n",
    "    pro_brd=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for i in pro_brd:\n",
    "        brand.append(i.text)\n",
    "    pro_des=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    for j in pro_des:\n",
    "        product_description.append(j.text)\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    for k in prices:\n",
    "        price.append(k.text)\n",
    "    disc=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "    for l in disc:\n",
    "        discount.append(l.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='ge-49M']\")\n",
    "    driver.get(nxt_button[page].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French Connection</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹680</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUCATI</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,296</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extoes</td>\n",
       "      <td>Modern Trendy Shoes Combo pack of 4 Sneakers F...</td>\n",
       "      <td>₹795</td>\n",
       "      <td>46% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>516 Trendy Star Perfect Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>54% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>aadi</td>\n",
       "      <td>170 Smart Grey Lace-Ups Casuals for Men Sneake...</td>\n",
       "      <td>₹298</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Bonexy</td>\n",
       "      <td>Multicolor Casual Shoes Mesh for Men Sneakers ...</td>\n",
       "      <td>₹450</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Stefano Rads</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹217</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>believe</td>\n",
       "      <td>171 Smart Tan Lace-Ups Casuals for Men Sneaker...</td>\n",
       "      <td>₹423</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                Product Description  \\\n",
       "0   French Connection                                   Sneakers For Men   \n",
       "1              DUCATI                                   Sneakers For Men   \n",
       "2              Chevit  Perfect & Affordable Combo Pack of 02 Pairs Sn...   \n",
       "3              Extoes  Modern Trendy Shoes Combo pack of 4 Sneakers F...   \n",
       "4        Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "..                ...                                                ...   \n",
       "95            Numenzo           516 Trendy Star Perfect Sneakers For Men   \n",
       "96               aadi  170 Smart Grey Lace-Ups Casuals for Men Sneake...   \n",
       "97             Bonexy  Multicolor Casual Shoes Mesh for Men Sneakers ...   \n",
       "98       Stefano Rads                                   Sneakers For Men   \n",
       "99            believe  171 Smart Tan Lace-Ups Casuals for Men Sneaker...   \n",
       "\n",
       "     Price Discount  \n",
       "0     ₹680  65% off  \n",
       "1   ₹1,296  63% off  \n",
       "2     ₹499  72% off  \n",
       "3     ₹795  46% off  \n",
       "4     ₹379  62% off  \n",
       "..     ...      ...  \n",
       "95    ₹398  54% off  \n",
       "96    ₹298  68% off  \n",
       "97    ₹450  57% off  \n",
       "98    ₹217  67% off  \n",
       "99    ₹423  68% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneaker=pd.DataFrame({})\n",
    "sneaker['Brand']=brand[:100]\n",
    "sneaker['Product Description']=product_description[:100]\n",
    "sneaker['Price']=price[:100]\n",
    "sneaker['Discount']=discount[:100]\n",
    "sneaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9.\"https://www.myntra.com/shoes\". Set price filter \"Rs 6649 to Rs 13099\" and color filter to \"Black\" and then scrap 100 shoes data. The data should include \"Brand\" of shoes, shoe short-description and price. Please not: Everything should done through code even the filtering for sneakers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import selenium \n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.myntra.com/shoes%22?f=Color%3ABlack_36454f&plaEnabled=false&rf=Price%3A6649.0_13099.0_6649.0%20TO%2013099.0%2C6612.0_13075.0_6612.0%20TO%2013075.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short-description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 7799Rs. 12999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 10121Rs. 13495(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Running Shoes</td>\n",
       "      <td>Rs. 7197Rs. 11995( 40 % OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR ZOOM Running</td>\n",
       "      <td>Rs. 10121Rs. 13495(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men KD13 EP Basketball Shoes</td>\n",
       "      <td>Rs. 12995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 6996Rs. 9995(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men REACT MILER Running Shoes</td>\n",
       "      <td>Rs. 8246Rs. 10995(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Mercedes Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women ZOOM SPAN 3 Running</td>\n",
       "      <td>Rs. 7195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nike</td>\n",
       "      <td>AIR ZOOM PEGASUS Running Shoes</td>\n",
       "      <td>Rs. 11495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Basketball</td>\n",
       "      <td>Rs. 12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JOYRIDE Running Shoes</td>\n",
       "      <td>Rs. 10496Rs. 14995(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women REACT Running Shoes</td>\n",
       "      <td>Rs. 8396Rs. 11995(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity Running</td>\n",
       "      <td>Rs. 10846Rs. 15495(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 7721Rs. 10295(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Textured Leather Formal Loafers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men VIPER COMPETITOR Training</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women REACT ESCAPE Running</td>\n",
       "      <td>Rs. 8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Mesh Fuse Training Or Gym Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men HOVR STRT Sportstyle Shoes</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Charged Impulse Knit</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Velocity Nitro Running</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>HOVR Guardian 2 Sports Shoes</td>\n",
       "      <td>Rs. 9599Rs. 11999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Perforated Mule Sneakers</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>HOVR Sonic 3 Running Shoes</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women Liquify Rebel Running</td>\n",
       "      <td>Rs. 7199Rs. 8999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Sneakers</td>\n",
       "      <td>Rs. 10995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Formal Derbys</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>HOVR Sonic 3 Running Shoes</td>\n",
       "      <td>Rs. 8799Rs. 10999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Liquify Running Shoes</td>\n",
       "      <td>Rs. 10999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women HOVR Rise 2 Training</td>\n",
       "      <td>Rs. 7999Rs. 9999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Charged Impulse Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Liberate Nitro Running</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men LQDCELL Training Shoes</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Women Black Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Colourblocked Driving Shoes</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Women UNO Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Woven-Design Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Women D'LITES 3.0 Sneakers</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Women Solid Block Heels</td>\n",
       "      <td>Rs. 8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Leather Block Heels</td>\n",
       "      <td>Rs. 7492Rs. 9990(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR MAX VIVA Sneakers</td>\n",
       "      <td>Rs. 12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Florsheim</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 6995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Women Sandals</td>\n",
       "      <td>Rs. 7499Rs. 14999(50% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Puma</td>\n",
       "      <td>SPEED Orbiter Running Shoes</td>\n",
       "      <td>Rs. 7149Rs. 12999(45% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                    Short-description  \\\n",
       "0              ALDO                  Men Leather Loafers   \n",
       "1              Nike           Men AIR ZOOM Running Shoes   \n",
       "2              Nike                  Women Running Shoes   \n",
       "3              Nike               Women AIR ZOOM Running   \n",
       "4              Nike         Men KD13 EP Basketball Shoes   \n",
       "5              Nike         Women AIR ZOOM Running Shoes   \n",
       "6              Nike        Men REACT MILER Running Shoes   \n",
       "7   PUMA Motorsport        Unisex Mercedes Running Shoes   \n",
       "8              Nike            Women ZOOM SPAN 3 Running   \n",
       "9              Nike       AIR ZOOM PEGASUS Running Shoes   \n",
       "10             Nike          Men JORDAN DELTA Basketball   \n",
       "11             Nike            Men JOYRIDE Running Shoes   \n",
       "12             Nike            Women REACT Running Shoes   \n",
       "13             Nike           Men React Infinity Running   \n",
       "14             Nike         Women AIR ZOOM Running Shoes   \n",
       "15          Bugatti  Men Textured Leather Formal Loafers   \n",
       "16         Skechers        Men VIPER COMPETITOR Training   \n",
       "17             Nike           Women REACT ESCAPE Running   \n",
       "18             Puma  Men Mesh Fuse Training Or Gym Shoes   \n",
       "19     UNDER ARMOUR       Men HOVR STRT Sportstyle Shoes   \n",
       "20     UNDER ARMOUR             Men Charged Impulse Knit   \n",
       "21             Puma           Men Velocity Nitro Running   \n",
       "22     UNDER ARMOUR         HOVR Guardian 2 Sports Shoes   \n",
       "23          Bugatti         Men Perforated Mule Sneakers   \n",
       "24     UNDER ARMOUR           HOVR Sonic 3 Running Shoes   \n",
       "25     UNDER ARMOUR          Women Liquify Rebel Running   \n",
       "26             Nike            Men JORDAN DELTA Sneakers   \n",
       "27     Hush Puppies                    Men Formal Derbys   \n",
       "28     Hush Puppies    Men Solid Leather Formal Slip-Ons   \n",
       "29          Bugatti      Men Solid Leather Formal Derbys   \n",
       "30     UNDER ARMOUR           HOVR Sonic 3 Running Shoes   \n",
       "31     UNDER ARMOUR            Men Liquify Running Shoes   \n",
       "32     UNDER ARMOUR           Women HOVR Rise 2 Training   \n",
       "33             Puma                    Men Running Shoes   \n",
       "34     UNDER ARMOUR        Charged Impulse Running Shoes   \n",
       "35             Puma                    Men Running Shoes   \n",
       "36             Puma           Men Liberate Nitro Running   \n",
       "37             Puma           Men LQDCELL Training Shoes   \n",
       "38          Bugatti                 Women Black Sneakers   \n",
       "39     Hush Puppies      Men Colourblocked Driving Shoes   \n",
       "40         Skechers                   Women UNO Sneakers   \n",
       "41  PUMA Motorsport         Unisex Woven-Design Sneakers   \n",
       "42         Skechers           Women D'LITES 3.0 Sneakers   \n",
       "43     Hush Puppies    Men Solid Leather Formal Slip-Ons   \n",
       "44          Bugatti              Women Solid Block Heels   \n",
       "45             Geox            Women Leather Block Heels   \n",
       "46             Nike          Women AIR MAX VIVA Sneakers   \n",
       "47        Florsheim      Men Solid Leather Formal Derbys   \n",
       "48        Cole Haan                        Women Sandals   \n",
       "49             Puma          SPEED Orbiter Running Shoes   \n",
       "\n",
       "                           Price  \n",
       "0     Rs. 7799Rs. 12999(40% OFF)  \n",
       "1    Rs. 10121Rs. 13495(25% OFF)  \n",
       "2   Rs. 7197Rs. 11995( 40 % OFF)  \n",
       "3    Rs. 10121Rs. 13495(25% OFF)  \n",
       "4                      Rs. 12995  \n",
       "5      Rs. 6996Rs. 9995(30% OFF)  \n",
       "6     Rs. 8246Rs. 10995(25% OFF)  \n",
       "7                       Rs. 7999  \n",
       "8                       Rs. 7195  \n",
       "9                      Rs. 11495  \n",
       "10                     Rs. 12495  \n",
       "11   Rs. 10496Rs. 14995(30% OFF)  \n",
       "12    Rs. 8396Rs. 11995(30% OFF)  \n",
       "13   Rs. 10846Rs. 15495(30% OFF)  \n",
       "14    Rs. 7721Rs. 10295(25% OFF)  \n",
       "15                      Rs. 7999  \n",
       "16                      Rs. 6999  \n",
       "17                      Rs. 8295  \n",
       "18                      Rs. 7999  \n",
       "19                      Rs. 9999  \n",
       "20                      Rs. 8999  \n",
       "21                     Rs. 10999  \n",
       "22    Rs. 9599Rs. 11999(20% OFF)  \n",
       "23                      Rs. 6999  \n",
       "24                     Rs. 10999  \n",
       "25     Rs. 7199Rs. 8999(20% OFF)  \n",
       "26                     Rs. 10995  \n",
       "27                      Rs. 9999  \n",
       "28                      Rs. 8999  \n",
       "29                      Rs. 9999  \n",
       "30    Rs. 8799Rs. 10999(20% OFF)  \n",
       "31                     Rs. 10999  \n",
       "32     Rs. 7999Rs. 9999(20% OFF)  \n",
       "33                      Rs. 7499  \n",
       "34                      Rs. 7999  \n",
       "35                      Rs. 6999  \n",
       "36                      Rs. 9999  \n",
       "37                      Rs. 6999  \n",
       "38                      Rs. 7999  \n",
       "39                      Rs. 8999  \n",
       "40                      Rs. 7999  \n",
       "41                      Rs. 7999  \n",
       "42                      Rs. 6999  \n",
       "43                      Rs. 9999  \n",
       "44                      Rs. 8499  \n",
       "45     Rs. 7492Rs. 9990(25% OFF)  \n",
       "46                     Rs. 12495  \n",
       "47                      Rs. 6995  \n",
       "48    Rs. 7499Rs. 14999(50% OFF)  \n",
       "49    Rs. 7149Rs. 12999(45% OFF)  "
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "start_page=0\n",
    "end_page=0\n",
    "for page in range(start_page,end_page+1): \n",
    "    \n",
    "    \n",
    "    \n",
    "    shoe_names=[]\n",
    "    s_desc=[]\n",
    "    short_desc=[]\n",
    "    price=[]\n",
    "    \n",
    "   \n",
    "    Names=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")\n",
    "    for i in Names[:100]:\n",
    "        shoe_names.append(i.text)\n",
    "    \n",
    "    \n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\")\n",
    "    for i in desc[:100]:\n",
    "        s_desc.append(i.text)\n",
    "    \n",
    "    for j in range(0,len(s_desc),2):\n",
    "        short_desc.append(s_desc[j])\n",
    "    \n",
    "    \n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    for i in desc[:100]:\n",
    "        price.append(i.text)\n",
    "    \n",
    "    nxt_button=driver.find_elements_by_xpath(\"//li[@class='pagination-number']/a\")\n",
    "    driver.get(nxt_button[page].get_attribute('href'))\n",
    "    \n",
    "            \n",
    "    \n",
    "    df=pd.DataFrame({'Brand': shoe_names[0:100],\n",
    "                    'Short-description': short_desc[0:100],\n",
    "                    'Price': price[0:100]})\n",
    "df[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Go to webpage https://www.amazon.in/Enter “Laptop” in the search field and then click the search icon.Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”. After setting the filters scrape first 10 laptops data.You have to scrape 3 attributes for each laptop:¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "title\n",
    "Ratings\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium \n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(' https://www.amazon.in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")  \n",
    "search_bar.clear()                                              \n",
    "search_bar.send_keys(\"laptops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button =driver.find_element_by_xpath('//span[@id=\"nav-search-submit-text\"]')      \n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Ratings=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in titles:\n",
    "    Title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in prices:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "UR=[]\n",
    "for i in urls:\n",
    "    UR.append(i.get_attribute('href'))\n",
    "for url in UR:\n",
    "    driver.get(url)\n",
    "    try:                  \n",
    "        rate=driver.find_element_by_xpath(\"//span[@id='acrCustomerReviewText']\")\n",
    "        rate.click()                                                      \n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "        Ratings.append(rating.text)\n",
    "        \n",
    "    except NoSuchElementException   as e:\n",
    "        Ratings.append(\"NO rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>86,790</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...</td>\n",
       "      <td>40,990</td>\n",
       "      <td>3.5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Legion 5 10th Gen Intel Core i7 15.6 in...</td>\n",
       "      <td>77,990</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td>88,990</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell Latitude 3410 14 Inch HD Intel Core i7 10...</td>\n",
       "      <td>44,999</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Renewed) Dell Latitude E6440 14 Inch Laptop (...</td>\n",
       "      <td>68,490</td>\n",
       "      <td>3.6 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Renewed) HP Pavilion 15-Cs1002txin 2018 15.6-...</td>\n",
       "      <td>77,990</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 10th Gen Intel Core i7...</td>\n",
       "      <td>82,490</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell G3 3500 Gaming 15.6inch 120hz FHD Display...</td>\n",
       "      <td>47,190</td>\n",
       "      <td>4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Lenovo Thinkpad Yoga S1 Laptop (CORE...</td>\n",
       "      <td>58,999</td>\n",
       "      <td>1 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   Price       Ratings\n",
       "0  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...  86,790  4.2 out of 5\n",
       "1  LifeDigital ZED AIR CX7 15.6 IPS FHD Screen Bl...  40,990  3.5 out of 5\n",
       "2  Lenovo Legion 5 10th Gen Intel Core i7 15.6 in...  77,990  4.3 out of 5\n",
       "3  ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...  88,990  4.3 out of 5\n",
       "4  Dell Latitude 3410 14 Inch HD Intel Core i7 10...  44,999     NO rating\n",
       "5  (Renewed) Dell Latitude E6440 14 Inch Laptop (...  68,490  3.6 out of 5\n",
       "6  (Renewed) HP Pavilion 15-Cs1002txin 2018 15.6-...  77,990     NO rating\n",
       "7  Lenovo IdeaPad Gaming 3 10th Gen Intel Core i7...  82,490  4.4 out of 5\n",
       "8  Dell G3 3500 Gaming 15.6inch 120hz FHD Display...  47,190    4 out of 5\n",
       "9  (Renewed) Lenovo Thinkpad Yoga S1 Laptop (CORE...  58,999    1 out of 5"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Title':Title[0:10],\n",
    "                'Price':price[0:10],\n",
    "                'Ratings':Ratings[0:10]})\n",
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
